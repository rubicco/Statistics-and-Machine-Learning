{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xzG4K-EMQVu9"
   },
   "source": [
    "# L2: Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGtyWJF4QVvC"
   },
   "source": [
    "Text classification is the task of sorting text documents into predefined classes. The concrete problem you will be working on in this lab is the classification of texts with respect to their political affiliation. The specific texts you are going to classify are speeches held in the [Riksdag](https://www.riksdagen.se/en/), the Swedish national legislature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uYbzoYdkQVvF"
   },
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7v2pqW7QVvH"
   },
   "source": [
    "The raw data for this lab comes from [The Riksdag’s Open Data](https://data.riksdagen.se/in-english/). We have tokenized the speeches and put them into two compressed [JSON](https://en.wikipedia.org/wiki/JSON) files:\n",
    "\n",
    "* `speeches-201718.json.bz2` (speeches from the 2017/2018 parliamentary session)\n",
    "* `speeches-201819.json.bz2` (ditto, from the 2018/2019 session)\n",
    "\n",
    "We start by loading these files into two separate data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y6Eeo302QVvK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "\n",
    "with bz2.open(\"speeches-201718.json.bz2\") as source:\n",
    "    speeches_201718 = pd.read_json(source)\n",
    "\n",
    "with bz2.open(\"speeches-201819.json.bz2\") as source:\n",
    "    speeches_201819 = pd.read_json(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PL9eUtkZQVvR"
   },
   "source": [
    "When you inspect the two data frames, you can see that there are three labelled columns: `id` (the official speech ID), `words` (the space-separated words of the speech), and `party` (the party of the speaker, represented by its customary abbreviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "umQBxE1gQVvT",
    "outputId": "0a31b884-c255-4f01-9e0c-98c7a530235d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>words</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H5-002-004</td>\n",
       "      <td>eders majestäter eders kungliga högheter herr ...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H5-003-001</td>\n",
       "      <td>aktuell debatt om situationen för ensamkommand...</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H5-003-002</td>\n",
       "      <td>herr talman och ledamöter jag vill börja med a...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H5-003-003</td>\n",
       "      <td>herr talman åhörare den här debatten handlar a...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H5-003-004</td>\n",
       "      <td>herr talman ansvar och rättssäkerhet är två or...</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              words party\n",
       "0  H5-002-004  eders majestäter eders kungliga högheter herr ...     S\n",
       "1  H5-003-001  aktuell debatt om situationen för ensamkommand...     V\n",
       "2  H5-003-002  herr talman och ledamöter jag vill börja med a...     S\n",
       "3  H5-003-003  herr talman åhörare den här debatten handlar a...     M\n",
       "4  H5-003-004  herr talman ansvar och rättssäkerhet är två or...    SD"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_201718.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZvuMsDRCQVvb"
   },
   "source": [
    "Throughout the lab, we will be using the speeches from 2017/2018 as our training data, and the speeches from 2018/2019 as our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BV51-KYGQVvc"
   },
   "outputs": [],
   "source": [
    "training_data, test_data = speeches_201718, speeches_201819"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ww1MDbV-QVvi"
   },
   "source": [
    "For later reference, we store the sorted list of party abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3Ze7Qz7NQVvk",
    "outputId": "dab01f84-da1f-49da-ca14-7ca3c3bbd074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'KD', 'L', 'M', 'MP', 'S', 'SD', 'V']\n"
     ]
    }
   ],
   "source": [
    "parties = sorted(training_data[\"party\"].unique())\n",
    "print(parties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZBQ5eHyQVvp",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Problem 1: Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSdE62MBQVvq"
   },
   "source": [
    "Your first task is to get to know the data better by plotting a simple visualization.\n",
    "\n",
    "If you are not familiar with the Swedish political system and the parties represented in the Riksdag in particular, then we suggest that you have a look at the Wikipedia article about the [2018 Swedish general election](https://en.wikipedia.org/wiki/2018_Swedish_general_election).\n",
    "\n",
    "For the lab, we ask you to compare the two data frames with respect to the distribution of the speeches over the different parties. Write code to generate two bar plots that visualize this information, one for the 2017/2018 speeches and one for the 2018/2019 speeches. Inspect the two plots, and compare them\n",
    "\n",
    "* to each other\n",
    "* to the results of the 2014 and the 2018 general elections\n",
    "\n",
    "Summarize your observations in a short text in the cell below.\n",
    "\n",
    "**Tip:** If you need help with creating bar plots, [Bar Plot using Pandas](https://dfrieds.com/data-visualizations/bar-plot-python-pandas) provides a useful tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HpkK_b-QVvr"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "B0LbbsDoQVvw",
    "outputId": "c9222004-7a90-42a9-b981-91dc2e2520b8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEbCAYAAAA21FQWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHPTNzHLk/wPv2PiMZYRIDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the distribution of the classes\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = training_data[\"party\"].unique()\n",
    "y1 = training_data[\"party\"].value_counts()\n",
    "x2 = test_data[\"party\"].unique()\n",
    "y2 = test_data[\"party\"].value_counts()\n",
    "r1 = np.arange(len(y1))\n",
    "r2 = [x + 0.25 for x in r1]\n",
    "\n",
    "plt.bar(r1, y1, color='blue', edgecolor='white',width = 0.5,\n",
    " label='2017-2018')\n",
    "plt.bar(r2, y2, color='yellow', edgecolor='black', width = 0.5,\n",
    "label='2018-2019')\n",
    "plt.xlabel('Parties', fontweight='bold')\n",
    "plt.xticks([r + 0.25 for r in range(len(y1))], x1)\n",
    "\n",
    "plt.title(\"Speeches VS Parties\", y=1.02)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jf8xjRAqQVv2"
   },
   "source": [
    "### Analysis\n",
    "\n",
    "We can see from the comparison on [Wikipedia](https://en.wikipedia.org/wiki/2018_Swedish_general_election) the changes between won seats as following:  \n",
    "\n",
    "**Increases:**  \n",
    "- SD: (13 seats)  \n",
    "- C: (9 seats)  \n",
    "- V: (7 seats)  \n",
    "- KD: (6 seats)  \n",
    "- L: (1 seats)\n",
    "\n",
    "**Decreases:**  \n",
    "- S: (13 seats)  \n",
    "- M: (14 seats)  \n",
    "- MP: (9 seats)\n",
    "\n",
    "We can see the MP lost 9 seats and in the plot above they also decreased their speeches in 2018 almost half, so it may be the reason the lost seats. Also, it is very clear to see that all parties in the **Increased** category keep their speech count nearly same like in 2017 with so small differences. On the other hand, S, M and MP decreased their speech activity very significantly. We can conclude this as speech counts effected very much to the results of election in 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jl6Pnry-QVv4",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Problem 2: Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BlqDpwahQVv4"
   },
   "source": [
    "You are now ready to train and evaluate a classifier. More specifically, we ask you to train a [Multinomial Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes) classifier. You will have to\n",
    "\n",
    "1. vectorize the speeches in the training data\n",
    "2. instantiate and fit the Naive Bayes model\n",
    "3. evaluate the model on the test data\n",
    "\n",
    "The scikit-learn library provides a convenience class [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) that allows you to solve the first two tasks with very compact code. For the evaluation you can use the function [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html), which will report per-class precision, recall and F1, as well as overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iZCk6ELgQVv6"
   },
   "source": [
    "### Implementation with Pipeline (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jF8TU3ksQVv7"
   },
   "outputs": [],
   "source": [
    "# TODO: Write code here to train and evaluate a Multinomial Naive Bayes classifier\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# define the steps for our pipeline\n",
    "steps = [(\"tfidfVectorizer\", CountVectorizer()), (\"multiNB\", MultinomialNB())]\n",
    "# define pipeline object\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SU-r749cQVwA"
   },
   "outputs": [],
   "source": [
    "# To implement a pipeline with sklearn we should \n",
    "# split the label from our data\n",
    "trainX, trainY = training_data.drop([\"party\"], axis=1), training_data[\"party\"]\n",
    "testX, testY = test_data.drop([\"party\"], axis=1), test_data[\"party\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "dn0bUMnZQVwE",
    "outputId": "2847d16b-a399-4217-f7ab-a8132f53ebfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfVectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('multiNB',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the parameters of pipeline steps\n",
    "params = {\n",
    "    \"multiNB__alpha\":1.0    \n",
    "}\n",
    "# fit the classifier by using the pipeline\n",
    "pipeline.fit(trainX[\"words\"], trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eB6FENV0QVwI"
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "preds = pipeline.predict(testX[\"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-9lxPZOxQVwL",
    "outputId": "940c3010-37d4-4610-b19c-3deae1004415"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7600259256258608"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation on train data\n",
    "pipeline.score(trainX[\"words\"], trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wgoaJyxeQVwQ",
    "outputId": "c897dcc9-a19c-407d-cd24-ac7ace799676"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4280792420327304"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation on test data\n",
    "pipeline.score(testX[\"words\"], testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "koK6ZjbrQVwT",
    "outputId": "8741fcfa-5a6b-4d6b-c3b2-278bb5f0efe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.63      0.04      0.07       671\n",
      "          KD       0.70      0.02      0.03       821\n",
      "           L       0.92      0.02      0.04       560\n",
      "           M       0.36      0.68      0.47      1644\n",
      "          MP       0.36      0.25      0.29       809\n",
      "           S       0.46      0.84      0.59      2773\n",
      "          SD       0.57      0.12      0.20      1060\n",
      "           V       0.59      0.15      0.24       950\n",
      "\n",
      "    accuracy                           0.43      9288\n",
      "   macro avg       0.57      0.26      0.24      9288\n",
      "weighted avg       0.52      0.43      0.34      9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(testY, preds, target_names=parties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fi8WhaoMQVwY"
   },
   "source": [
    "### Standard Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5qm2SW0EQVwZ",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# define and fit vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(training_data[\"words\"])\n",
    "# data\n",
    "X_train = vectorizer.transform(training_data[\"words\"])\n",
    "y_train = training_data[\"party\"]\n",
    "\n",
    "X_test = vectorizer.transform(test_data[\"words\"])\n",
    "y_test = test_data[\"party\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3TutArqSQVwd",
    "outputId": "4c27f917-0e25-461d-8a47-0544f0463444"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbClassifier = MultinomialNB()\n",
    "nbClassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PKshvtRYQVwh"
   },
   "outputs": [],
   "source": [
    "stdPreds = nbClassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qpVl-UZxQVwj",
    "outputId": "6810983f-ec3f-4743-ba21-8e5ed0443e96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4280792420327304"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(stdPreds == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YeRpnXbFQVwn"
   },
   "source": [
    "Would you have expected the results that you got?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4l7ZJFysQVwo"
   },
   "source": [
    "### Analysis\n",
    "In this task we implement a Multinomial Bayes classifier with default choice of parameters.\n",
    "\n",
    "We can now evaluate the classifier using the above results. The accuracy is approximately 43% which is quite low. One can say that we could expected that because of the unbalanced data. Accuracy is just a number though. In order to have a more clear picture, we should compare the accuracies of different models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5R45PgWdQVwq"
   },
   "source": [
    "## Problem 3: Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRVkp-loQVws"
   },
   "source": [
    "Evaluation metrics such as accuracy should not be understood as absolute measures of performance, but should be used only to compare different classifiers. When other classifiers are not available, a simple baseline for text classification is **Most Frequent Class (MFC)**. One way to think of this baseline is as a classifier that, for every document, predicts that class which appears most often in the training data.\n",
    "\n",
    "Determine the most frequent class in the 2017/2018 data. What is the accuracy of the MFC baseline on the test data? Given this baseline accuracy, how do you assess the results of the Naive Bayes classifier from Problem&nbsp;2? Answer with a short text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "xgN8i15CQVwt",
    "outputId": "b95faaeb-0c3d-4b13-8895-596121c6e7d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Frequent Class (MFC): S \n",
      "MFC Accuracy: 0.298557278208441\n"
     ]
    }
   ],
   "source": [
    "freqClass = speeches_201718[\"party\"].value_counts().idxmax()\n",
    "MFC_accuracy = test_data[\"party\"].value_counts()[freqClass]/test_data.shape[0]\n",
    "\n",
    "print(\"Most Frequent Class (MFC): \" + freqClass, \"\\nMFC Accuracy: \" + str(MFC_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SzRy1VPBQVwx"
   },
   "source": [
    "### Analysis\n",
    "\n",
    "It is obvious that a baseline classifier will give most of the times poor performance. In that case the accuracy of the MFC baseline is approximately 0.3 which is lower by 13% from the Bayes classifier. Therefore, it seems that the structure of the data causes problem in order to predict the classes correct. We can also comment that for the given problem, the accuracy of the Bayes classifier is quite good, even if the 43% seems low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A8zYXpu4QVwy"
   },
   "source": [
    "## Problem 4: Creating a balanced data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwRQ6clTQVw0"
   },
   "source": [
    "As you saw in Problem&nbsp;1, the distribution of the speeches over the eight different parties (classes) is imbalanced. One technique used to alleviate this is **undersampling**, in which one randomly removes samples from over-represented classes until all classes are represented with the same number of samples.\n",
    "\n",
    "Implement undersampling to create a balanced subset of the training data. Rerun the evaluation from Problem&nbsp;2 on the balanced data and compare the results. Discuss your findings in a short text. Would you argue that undersampling make sense for the task of predicting the party of a speaker?\n",
    "\n",
    "**Hint:** Your balanced subset should consist of 5,752 speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3rYgveHcQVw1"
   },
   "outputs": [],
   "source": [
    "lowestCount = training_data[\"party\"].value_counts()[-1]\n",
    "labels = training_data[\"party\"].unique()\n",
    "newTrain = pd.DataFrame()\n",
    "for l in labels:\n",
    "    newTrain = newTrain.append(training_data[training_data[\"party\"]==l].sample(lowestCount, replace=False, random_state=12345))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fse1CrujQVw5",
    "outputId": "05c524c7-50e5-4d3a-99e4-f5c18763af77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5752, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0RytxsyCQVw8",
    "outputId": "89a7bb8f-832e-4962-d70b-5443c0d80f71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40654608096468564"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of balanced newTrain data with test data\n",
    "pipeline.fit(newTrain[\"words\"], newTrain[\"party\"])\n",
    "preds = pipeline.predict(testX[\"words\"])\n",
    "pipeline.score(testX[\"words\"], testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "yMVrpkftQVxB",
    "outputId": "b8ea2bce-c72b-4f5f-e819-c7d7074dcc79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.28      0.43      0.34       671\n",
      "          KD       0.32      0.39      0.35       821\n",
      "           L       0.28      0.43      0.34       560\n",
      "           M       0.40      0.51      0.45      1644\n",
      "          MP       0.35      0.39      0.37       809\n",
      "           S       0.80      0.28      0.42      2773\n",
      "          SD       0.43      0.42      0.43      1060\n",
      "           V       0.39      0.57      0.46       950\n",
      "\n",
      "    accuracy                           0.41      9288\n",
      "   macro avg       0.41      0.43      0.39      9288\n",
      "weighted avg       0.49      0.41      0.41      9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testY, preds, target_names=parties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5SOLfv7QVxE"
   },
   "source": [
    "### Analysis\n",
    "\n",
    "Undersampling provides us better recall scores, and better balance between precision and recall. We can see this effect from f1-scores. Although we have lower accuracy, we have higher f1-scores which makes our classifier more balanced.\n",
    "\n",
    "Undersampling is a really simple techinque but it can work efficient enough in many causes. In that case thought, it seems that that method can not help. A reason could be that we train our classifier in less data than before(5752 instead of 12343). Moreover, using the count Vectorization technique, the number of features we have is really high(75125)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f2zku-b0QVxF"
   },
   "source": [
    "## Problem 5: Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ARQjUqaxQVxG"
   },
   "source": [
    "A **confusion matrix** is a specific table layout that is useful when analysing the performance of a classifier. In this matrix, both the rows and the columns correspond to classes, and each cell $(i, j)$ states how many times a sample with gold-standard class $i$ was predicted as belonging to class $j$.\n",
    "\n",
    "In scitkit-learn, the confusion matrix of a classifier is computed by the function [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html).\n",
    "\n",
    "Your task is to use the confusion matrix to find, for each given party $p$ in the Riksdag, that other party $p'$ which the classifier that you trained in Problem&nbsp;4 most often confuses $p$ with when it predicts the party of a speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-WwCRqHQVxG"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(testY, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "fRvfTE9GQVxJ",
    "outputId": "d00a30b3-57e9-4f73-f30a-9a05104b9920"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>KD</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>MP</th>\n",
       "      <th>S</th>\n",
       "      <th>SD</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>288</td>\n",
       "      <td>57</td>\n",
       "      <td>47</td>\n",
       "      <td>105</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KD</th>\n",
       "      <td>87</td>\n",
       "      <td>324</td>\n",
       "      <td>55</td>\n",
       "      <td>158</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>66</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>52</td>\n",
       "      <td>47</td>\n",
       "      <td>241</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>192</td>\n",
       "      <td>163</td>\n",
       "      <td>130</td>\n",
       "      <td>831</td>\n",
       "      <td>84</td>\n",
       "      <td>40</td>\n",
       "      <td>110</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MP</th>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>104</td>\n",
       "      <td>316</td>\n",
       "      <td>72</td>\n",
       "      <td>47</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>202</td>\n",
       "      <td>221</td>\n",
       "      <td>184</td>\n",
       "      <td>491</td>\n",
       "      <td>321</td>\n",
       "      <td>789</td>\n",
       "      <td>205</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>98</td>\n",
       "      <td>188</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>449</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>53</td>\n",
       "      <td>65</td>\n",
       "      <td>59</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>71</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C   KD    L    M   MP    S   SD    V\n",
       "C   288   57   47  105   47   18   55   54\n",
       "KD   87  324   55  158   33   24   66   74\n",
       "L    52   47  241   63   32   10   45   70\n",
       "M   192  163  130  831   84   40  110   94\n",
       "MP   60   56   57  104  316   72   47   97\n",
       "S   202  221  184  491  321  789  205  360\n",
       "SD   90   86   98  188   39   16  449   94\n",
       "V    53   65   59  113   35   16   71  538"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfConfMatrix = pd.DataFrame(conf_matrix, index=parties, columns=parties)\n",
    "dfConfMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "LUuhy8MJQVxM",
    "outputId": "a561b387-e772-4a40-8284-46801b378b55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', 'M'),\n",
       " ('KD', 'M'),\n",
       " ('L', 'V'),\n",
       " ('M', 'C'),\n",
       " ('MP', 'M'),\n",
       " ('S', 'M'),\n",
       " ('SD', 'M'),\n",
       " ('V', 'M')]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostConfusingParties = [(k, v[v!=v[k]].idxmax()) for (k,v) in dfConfMatrix.iterrows()]\n",
    "mostConfusingParties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3MWf9AxjQVxO"
   },
   "source": [
    "The diagonal of the confusion matrix gives us the proportion of each class which classified correctly. In that task, we went through each row in order to find the most common class for each missclassified class. \n",
    "\n",
    "In the list above, the first element in the tuple is the true label, and the second is the most common label when the class is misclassified. As we cna see in almost all the classes, the \"misleading\" class is \"M\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELJbLVqBQVxP"
   },
   "source": [
    "## Problem 6: Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIBo4rUTQVxQ"
   },
   "source": [
    "Until now, you have been using the vectorizer and the Naive Bayes classifier with their default hyperparameters. When working with real-world applications, you would want to find settings for the hyperparameters that maximize the performance for the task at hand.\n",
    "\n",
    "Manually tweaking the hyperparameters of the various components of a vectorizer–classifier pipeline can be cumbersome. However, scikit-learn makes it possible to run an exhaustive search for the best hyperparameters over a grid of possible values. This method is known as **grid search**.\n",
    "\n",
    "The hyperparameters of a pipeline should never be tuned on the final test set. (Why would that be a bad idea?) Instead, one should either use a separate validation set, or run cross-validation over different folds. Here we will use cross-validation.\n",
    "\n",
    "Implement a grid search with 5-fold cross-validation to find the optimal parameters in a grid defined by the following choices for the hyperparameters:\n",
    "\n",
    "* In the vectorizer, try a set-of-words model instead of the default bag-of-words model (two possible parameter values).\n",
    "* Also in the vectorizer, try extracting $n$-grams up to $n = 2$ (two possible parameter values).\n",
    "* In the Naive Bayes classifier, try using additive smoothing with $\\alpha \\in \\{1, 0{.}1\\}$ (two possible parameter values).\n",
    "\n",
    "Use the class [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) from the scikit-learn library. Print the results of your best model, along with the parameter values that yielded these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNvFhwKvQVxR"
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"tfidfVectorizer__ngram_range\": [(1,1), (1,2)],\n",
    "    \"tfidfVectorizer__binary\": [True, False],\n",
    "    \"multiNB__alpha\": [1,0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "WOvCwb5pQVxT",
    "outputId": "62549ca5-72fb-4ebc-b479-2672cbd1a45b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidfVectorizer',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accen...\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('multiNB',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'multiNB__alpha': [1, 0.1],\n",
       "                         'tfidfVectorizer__binary': [True, False],\n",
       "                         'tfidfVectorizer__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(pipeline, param_grid=parameters, cv=5, verbose=1)\n",
    "grid.fit(training_data[\"words\"], training_data[\"party\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "nr2E02nqQVxV",
    "outputId": "cca4e293-8b65-4e30-c3cc-a2a45a147849"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_multiNB__alpha</th>\n",
       "      <th>param_tfidfVectorizer__binary</th>\n",
       "      <th>param_tfidfVectorizer__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.238394</td>\n",
       "      <td>0.052837</td>\n",
       "      <td>0.550300</td>\n",
       "      <td>0.022317</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'multiNB__alpha': 1, 'tfidfVectorizer__binary...</td>\n",
       "      <td>0.474302</td>\n",
       "      <td>0.468206</td>\n",
       "      <td>0.471851</td>\n",
       "      <td>0.474878</td>\n",
       "      <td>0.455393</td>\n",
       "      <td>0.468930</td>\n",
       "      <td>0.007161</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.697752</td>\n",
       "      <td>0.160871</td>\n",
       "      <td>1.345931</td>\n",
       "      <td>0.031226</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'multiNB__alpha': 1, 'tfidfVectorizer__binary...</td>\n",
       "      <td>0.397005</td>\n",
       "      <td>0.388821</td>\n",
       "      <td>0.397327</td>\n",
       "      <td>0.410454</td>\n",
       "      <td>0.390511</td>\n",
       "      <td>0.396824</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.203430</td>\n",
       "      <td>0.024813</td>\n",
       "      <td>0.548748</td>\n",
       "      <td>0.022635</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'multiNB__alpha': 1, 'tfidfVectorizer__binary...</td>\n",
       "      <td>0.514771</td>\n",
       "      <td>0.509923</td>\n",
       "      <td>0.521669</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.486212</td>\n",
       "      <td>0.506522</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.553581</td>\n",
       "      <td>0.119712</td>\n",
       "      <td>1.341935</td>\n",
       "      <td>0.043862</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'multiNB__alpha': 1, 'tfidfVectorizer__binary...</td>\n",
       "      <td>0.420478</td>\n",
       "      <td>0.404617</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>0.419773</td>\n",
       "      <td>0.403082</td>\n",
       "      <td>0.411407</td>\n",
       "      <td>0.007391</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.215343</td>\n",
       "      <td>0.019373</td>\n",
       "      <td>0.547394</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'multiNB__alpha': 0.1, 'tfidfVectorizer__bina...</td>\n",
       "      <td>0.591259</td>\n",
       "      <td>0.622924</td>\n",
       "      <td>0.597408</td>\n",
       "      <td>0.563614</td>\n",
       "      <td>0.547445</td>\n",
       "      <td>0.584542</td>\n",
       "      <td>0.026445</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.619079</td>\n",
       "      <td>0.167821</td>\n",
       "      <td>1.353370</td>\n",
       "      <td>0.028299</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'multiNB__alpha': 0.1, 'tfidfVectorizer__bina...</td>\n",
       "      <td>0.575071</td>\n",
       "      <td>0.575537</td>\n",
       "      <td>0.586067</td>\n",
       "      <td>0.553485</td>\n",
       "      <td>0.545418</td>\n",
       "      <td>0.567123</td>\n",
       "      <td>0.015163</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.209323</td>\n",
       "      <td>0.026077</td>\n",
       "      <td>0.556095</td>\n",
       "      <td>0.023086</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'multiNB__alpha': 0.1, 'tfidfVectorizer__bina...</td>\n",
       "      <td>0.603804</td>\n",
       "      <td>0.625759</td>\n",
       "      <td>0.592548</td>\n",
       "      <td>0.562804</td>\n",
       "      <td>0.545823</td>\n",
       "      <td>0.586162</td>\n",
       "      <td>0.028606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.570942</td>\n",
       "      <td>0.180662</td>\n",
       "      <td>1.354736</td>\n",
       "      <td>0.032085</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'multiNB__alpha': 0.1, 'tfidfVectorizer__bina...</td>\n",
       "      <td>0.582760</td>\n",
       "      <td>0.602673</td>\n",
       "      <td>0.596193</td>\n",
       "      <td>0.559157</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.581706</td>\n",
       "      <td>0.016458</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "0       2.238394      0.052837  ...        0.007161                6\n",
       "1       8.697752      0.160871  ...        0.007614                8\n",
       "2       2.203430      0.024813  ...        0.012359                5\n",
       "3       8.553581      0.119712  ...        0.007391                7\n",
       "4       2.215343      0.019373  ...        0.026445                2\n",
       "5       8.619079      0.167821  ...        0.015163                4\n",
       "6       2.209323      0.026077  ...        0.028606                1\n",
       "7       8.570942      0.180662  ...        0.016458                3\n",
       "\n",
       "[8 rows x 16 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "V1wxQgDCQVxY",
    "outputId": "b952dac1-85c9-4162-e696-798311c06e78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.39      0.27      0.32       671\n",
      "          KD       0.45      0.24      0.31       821\n",
      "           L       0.37      0.26      0.30       560\n",
      "           M       0.44      0.58      0.50      1644\n",
      "          MP       0.32      0.46      0.38       809\n",
      "           S       0.61      0.65      0.63      2773\n",
      "          SD       0.49      0.43      0.45      1060\n",
      "           V       0.50      0.42      0.46       950\n",
      "\n",
      "    accuracy                           0.48      9288\n",
      "   macro avg       0.45      0.41      0.42      9288\n",
      "weighted avg       0.48      0.48      0.48      9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = grid.best_estimator_.predict(testX[\"words\"])\n",
    "print(classification_report(testY, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "M3oA5BK2QVxa",
    "outputId": "6e1a11ab-a5b6-405a-b4db-dad81b6e9f5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multiNB__alpha': 0.1,\n",
       " 'tfidfVectorizer__binary': False,\n",
       " 'tfidfVectorizer__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tt6wlbl6QVxb"
   },
   "source": [
    "## problem 6: Try to improve your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htwCyvIkQVxc"
   },
   "source": [
    "Scikit-learn makes it easy to test different vectorizer–classifier pipelines – among other things, it includes different types of logistic regression classifiers, support vector machines, and decision trees. Browse the library to see which methods are supported.\n",
    "\n",
    "Build a pipeline that you find interesting, and use grid search to find optimal settings for the hyperparameters. Print the results of your best model. Did you manage to get better results than the ones that you obtained in Problem&nbsp;5? Answer with a short text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6gvz2jHsQVxc"
   },
   "source": [
    "### Preprocess Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "iNdawi5VQVxe",
    "outputId": "567115e7-43d6-4625-f9a4-ec361fcbfd8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "# define stemmer will be used in preprocessing\n",
    "stemmer = SnowballStemmer(\"swedish\")\n",
    "# define punctuation table\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "# define stopwords\n",
    "stopwords_sw = set(stopwords.words(\"swedish\"))\n",
    "\n",
    "def preprocess(text):\n",
    "    words = []\n",
    "    for t in word_tokenize(text):\n",
    "        t_ = t.lower().translate(table)\n",
    "        if(not t_ in stopwords_sw and t_.isalpha()):\n",
    "            words.append(stemmer.stem(t_))\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bs65wC4xQVxf"
   },
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhIkKrmdQVxh"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "Ol9olF1mQVxj",
    "outputId": "8441260e-097d-4a58-d5b7-e44ec9a65d61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomForest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinomialNB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  6.5min finished\n"
     ]
    }
   ],
   "source": [
    "countVectorizer = CountVectorizer(tokenizer=preprocess)\n",
    "pipelines = [\n",
    "    (\"randomForest\", \n",
    "     Pipeline([(\"countVectorizer\", countVectorizer), \n",
    "               (\"classifier\", RandomForestClassifier(n_estimators=200, \n",
    "                                                     max_depth=3, \n",
    "                                                     random_state=0))])),\n",
    "    (\"linearSVC\", \n",
    "     Pipeline([(\"countVectorizer\", countVectorizer), \n",
    "               (\"classifier\", LinearSVC(max_iter=10000))])),\n",
    "    (\"multinomialNB\", \n",
    "     Pipeline([(\"countVectorizer\", countVectorizer), \n",
    "               (\"classifier\", MultinomialNB())])),\n",
    "    (\"logisticRegression\", \n",
    "     Pipeline([(\"countVectorizer\", countVectorizer), \n",
    "               (\"classifier\", LogisticRegression(random_state=0, \n",
    "                                                 multi_class=\"multinomial\", \n",
    "                                                 solver=\"lbfgs\", \n",
    "                                                 max_iter=350))]))    \n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(pipelines)))\n",
    "entries = []\n",
    "\n",
    "for (model_name, pipeline) in pipelines:\n",
    "    print(model_name)\n",
    "    accuracies = cross_val_score(pipeline, \n",
    "                                 training_data[\"words\"], \n",
    "                                 training_data[\"party\"], \n",
    "                                 scoring=\"accuracy\", cv=CV, \n",
    "                                 verbose=1)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "    cv_df = pd.DataFrame(entries, columns=[\"model_name\", \"fold_idx\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "-_UcCUNGQVxl",
    "outputId": "7c0bf540-7e32-47cc-dfc5-82b6b02b0177"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEHCAYAAAC9TnFRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nm4YaTp0sj/IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ryiuqGaaQVxo"
   },
   "source": [
    "#### Analysis\n",
    "\n",
    "First we did preprocessing in the data and we got better results for Naive Bayes classifier which is implemented in previous task. We can see that in the plot, avarage accuracy of cross-validation is better.  \n",
    "In model selection, we got better results for logistic regression and in the next topic we are going to use this classifier to fit its hyperparameters and we will test the best model with best hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Z2GBhM-QVxq"
   },
   "source": [
    "### Best Model (Logistic Regression) Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "AkFqdIhqQVxr",
    "outputId": "e69132ee-a2c3-48df-efbc-4808bbdf2471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 194.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('countVectorizer',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accen...\n",
       "                                                           multi_class='multinomial',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=0,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'classifier__C': [0.1, 1, 10],\n",
       "                         'countVectorizer__binary': [True, False],\n",
       "                         'countVectorizer__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineLogistic = pipelines[3][1]\n",
    "\n",
    "parameters = {\n",
    "    \"countVectorizer__ngram_range\": [(1,1), (1,2)],\n",
    "    \"countVectorizer__binary\": [True, False],\n",
    "    \"classifier__C\": [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gridBest = GridSearchCV(pipelineLogistic, param_grid=parameters, cv=5, verbose=1)\n",
    "gridBest.fit(training_data[\"words\"], training_data[\"party\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "colab_type": "code",
    "id": "-cPEfqWCQVxv",
    "outputId": "63abd264-a650-4e6b-c1a0-d37beaccd79b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_countVectorizer__binary</th>\n",
       "      <th>param_countVectorizer__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.715725</td>\n",
       "      <td>0.264493</td>\n",
       "      <td>6.969098</td>\n",
       "      <td>0.306837</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 0.1, 'countVectorizer__binar...</td>\n",
       "      <td>0.614731</td>\n",
       "      <td>0.642770</td>\n",
       "      <td>0.625354</td>\n",
       "      <td>0.620340</td>\n",
       "      <td>0.576237</td>\n",
       "      <td>0.615896</td>\n",
       "      <td>0.021928</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>243.844273</td>\n",
       "      <td>3.828050</td>\n",
       "      <td>7.353055</td>\n",
       "      <td>0.133572</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 0.1, 'countVectorizer__binar...</td>\n",
       "      <td>0.610279</td>\n",
       "      <td>0.633860</td>\n",
       "      <td>0.616849</td>\n",
       "      <td>0.625608</td>\n",
       "      <td>0.585969</td>\n",
       "      <td>0.614518</td>\n",
       "      <td>0.016338</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.017247</td>\n",
       "      <td>1.795527</td>\n",
       "      <td>6.791278</td>\n",
       "      <td>0.282562</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 0.1, 'countVectorizer__binar...</td>\n",
       "      <td>0.603399</td>\n",
       "      <td>0.631025</td>\n",
       "      <td>0.610774</td>\n",
       "      <td>0.608590</td>\n",
       "      <td>0.557989</td>\n",
       "      <td>0.602366</td>\n",
       "      <td>0.024080</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>265.812694</td>\n",
       "      <td>6.037812</td>\n",
       "      <td>7.111387</td>\n",
       "      <td>0.237812</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 0.1, 'countVectorizer__binar...</td>\n",
       "      <td>0.608256</td>\n",
       "      <td>0.634265</td>\n",
       "      <td>0.620089</td>\n",
       "      <td>0.604133</td>\n",
       "      <td>0.569749</td>\n",
       "      <td>0.607308</td>\n",
       "      <td>0.021496</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.611929</td>\n",
       "      <td>0.930848</td>\n",
       "      <td>6.684204</td>\n",
       "      <td>0.261139</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 1, 'countVectorizer__binary'...</td>\n",
       "      <td>0.600162</td>\n",
       "      <td>0.628190</td>\n",
       "      <td>0.614419</td>\n",
       "      <td>0.589546</td>\n",
       "      <td>0.555150</td>\n",
       "      <td>0.597505</td>\n",
       "      <td>0.024861</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>286.030347</td>\n",
       "      <td>7.997707</td>\n",
       "      <td>7.097815</td>\n",
       "      <td>0.306075</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 1, 'countVectorizer__binary'...</td>\n",
       "      <td>0.616754</td>\n",
       "      <td>0.635480</td>\n",
       "      <td>0.625759</td>\n",
       "      <td>0.629254</td>\n",
       "      <td>0.576237</td>\n",
       "      <td>0.616706</td>\n",
       "      <td>0.021109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79.297661</td>\n",
       "      <td>1.908873</td>\n",
       "      <td>6.774924</td>\n",
       "      <td>0.279334</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 1, 'countVectorizer__binary'...</td>\n",
       "      <td>0.601781</td>\n",
       "      <td>0.614824</td>\n",
       "      <td>0.596193</td>\n",
       "      <td>0.589141</td>\n",
       "      <td>0.544607</td>\n",
       "      <td>0.589322</td>\n",
       "      <td>0.023876</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>319.549199</td>\n",
       "      <td>8.316026</td>\n",
       "      <td>7.114149</td>\n",
       "      <td>0.299405</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 1, 'countVectorizer__binary'...</td>\n",
       "      <td>0.611898</td>\n",
       "      <td>0.637505</td>\n",
       "      <td>0.619684</td>\n",
       "      <td>0.605348</td>\n",
       "      <td>0.557178</td>\n",
       "      <td>0.606336</td>\n",
       "      <td>0.026817</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80.708249</td>\n",
       "      <td>0.587098</td>\n",
       "      <td>6.738414</td>\n",
       "      <td>0.273950</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 10, 'countVectorizer__binary...</td>\n",
       "      <td>0.597329</td>\n",
       "      <td>0.611989</td>\n",
       "      <td>0.601458</td>\n",
       "      <td>0.579822</td>\n",
       "      <td>0.536496</td>\n",
       "      <td>0.585433</td>\n",
       "      <td>0.026562</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>325.308783</td>\n",
       "      <td>7.315101</td>\n",
       "      <td>7.112777</td>\n",
       "      <td>0.285973</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 10, 'countVectorizer__binary...</td>\n",
       "      <td>0.618373</td>\n",
       "      <td>0.633860</td>\n",
       "      <td>0.626569</td>\n",
       "      <td>0.629254</td>\n",
       "      <td>0.578670</td>\n",
       "      <td>0.617354</td>\n",
       "      <td>0.019975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>88.869833</td>\n",
       "      <td>2.525324</td>\n",
       "      <td>6.756126</td>\n",
       "      <td>0.303045</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 10, 'countVectorizer__binary...</td>\n",
       "      <td>0.589235</td>\n",
       "      <td>0.604698</td>\n",
       "      <td>0.580397</td>\n",
       "      <td>0.572123</td>\n",
       "      <td>0.532441</td>\n",
       "      <td>0.575792</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>374.339132</td>\n",
       "      <td>8.763710</td>\n",
       "      <td>7.183652</td>\n",
       "      <td>0.456177</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 10, 'countVectorizer__binary...</td>\n",
       "      <td>0.609065</td>\n",
       "      <td>0.635480</td>\n",
       "      <td>0.618874</td>\n",
       "      <td>0.603728</td>\n",
       "      <td>0.556772</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.026318</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "0       51.715725      0.264493  ...        0.021928                3\n",
       "1      243.844273      3.828050  ...        0.016338                4\n",
       "2       61.017247      1.795527  ...        0.024080                8\n",
       "3      265.812694      6.037812  ...        0.021496                5\n",
       "4       69.611929      0.930848  ...        0.024861                9\n",
       "5      286.030347      7.997707  ...        0.021109                2\n",
       "6       79.297661      1.908873  ...        0.023876               10\n",
       "7      319.549199      8.316026  ...        0.026817                6\n",
       "8       80.708249      0.587098  ...        0.026562               11\n",
       "9      325.308783      7.315101  ...        0.019975                1\n",
       "10      88.869833      2.525324  ...        0.024202               12\n",
       "11     374.339132      8.763710  ...        0.026318                7\n",
       "\n",
       "[12 rows x 16 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gridBest.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "DZh2YoMUQVxx",
    "outputId": "67c8ab46-990f-4056-9da6-1d7861f258c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.48      0.32      0.38       671\n",
      "          KD       0.56      0.22      0.32       821\n",
      "           L       0.47      0.33      0.39       560\n",
      "           M       0.50      0.54      0.52      1644\n",
      "          MP       0.37      0.39      0.38       809\n",
      "           S       0.54      0.81      0.65      2773\n",
      "          SD       0.52      0.42      0.46      1060\n",
      "           V       0.64      0.36      0.46       950\n",
      "\n",
      "    accuracy                           0.52      9288\n",
      "   macro avg       0.51      0.42      0.45      9288\n",
      "weighted avg       0.52      0.52      0.50      9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_bestClassifier = gridBest.best_estimator_.predict(test_data[\"words\"])\n",
    "print(classification_report(test_data[\"party\"], preds_bestClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "bC17uKxMQVxz",
    "outputId": "b315e088-f41e-4b4c-c6fa-a04ea7e82bf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 10,\n",
       " 'countVectorizer__binary': True,\n",
       " 'countVectorizer__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridBest.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ezv-BVq9Yetd"
   },
   "source": [
    "**NOTE:**\n",
    "\n",
    "Running last grid search takes too long time. In order to eliminate \"no convergence, increase max_iter\" warning, we increased it. But training time can be shorten by setting max_iter=100. It throws convergence warning, but accuracy will not change that much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-sEPUYugQVx1"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Please read the section ‘General information’ on the ‘Labs’ page of the course website before submitting this notebook!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "flB0mBrZY0KL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TM-L2_rubicco.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
